---
title: Cleaning Data
author: Benjamin Schmidt
date: 2019-01-19
output: pdf_document
---

```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(eval = FALSE, warning = FALSE, message = FALSE)
```

# Cleaning Data

## Overview

First, some general background.

It is a truism that for humanities data analysis (and most other types, for that matter), at least 75% of your effort will go into *cleaning* rather than analyzing data.

Most of the work of cleaning data is necessarily irregular. Different types of data all have their own their problems.

Some of the most common include the following.

#### Character encoding

How does the text represent symbols like curly quotation marks or non-English characters like the German "eszett" (ÃŸ)? In the last decade, the world has coalesced around the **unicode standard**, which provides a coherent way to represent millions of characters from written languages around the globe. (And plenty of other places, as well; emoji, for instance, are assigned their own unicode space). ASCII, the traditional character set of 1980s American computing, is a subset of Unicode and so works well inside it. Other characters (things like curly quotes) may cause problems. If you find yourself working with a file in a different character encoding, R generally allows you to read the file in by specifying the name of the standard. You will have to Google around.

#### Record formats

Even when you're given perfectly formatted data, you may experience some trouble reading it in.

In R, most problems will arise from conventions around **commenting** and **quoting** files. When you use `read_table` and encounter errors, most often you want to adjust the arguments to comment and quote characters, which instructs the parser to ignore the "#" sign and quotation marks. Note that some files do use quotation marks as a "quote" character, such as the New Bedford whaling data we looked at in class.

Even the simplest of characters can cause problems. If the file was created on a Macintosh, you may find that the end-of-line files aren't behaving as you would expect. This has to do with the so-called "carriage return" character (called `\r` in regular expressions, as opposed to `\n`, the standard newline.

> History moment: the reason for the peculiar behavior of the carriage return and newline has to do with the typewriter operations underlying modern computing: 
> the `\r` symbol was supposed to move the typewriter head to the beginning of the line, while the `\n` newline character pushes the typewriter head down.
> In practice, `\n` is sufficient to do both; there's actually a third character, the formfeed (`\f`), that usually takes on the job of dropping the
> cursor down a line. You will almost never see it in use, but it can be handy to insert from time to time if you need your own record breaks.

#### Inconsistent category labels

This is the biggest one, and one that you'll encounter in the whaling log data.

#### Date-time and other "type" formats

What is the data type for a year? You might reasonably expect it to be a number. But in fact, you'll often find that dates.

In converting messy dates, you'll frequently have to use regular expressions. 

When creating data yourself, you should use ISO 8601, which uses a "year-month-day" format. That is: Europeans and Americans differ about whether
Pearl Harbor happened on `12/7/41` or `7/12/41`; the only sound response if you are creating data is to use `1945-12-07`.

In the example data in the excersises, you'll see an example of this in the data from the New Bedford Whaling Museum.

## Data cleaning in R

### Reading files.

Depending on how the data you wish to read in is structured, you will typically use one of three functions in R to read it in.

How do you read in data? Generally, the information you want will be either on your hard drive (as when you format it) or on the Internet. For our first example, we'll be looking at a well-formatted CSV online.

There's some good descriptive data about people, which suggests a chance for something about bodies--measurements, physical descriptions, and ages all have interesting interplays. That will be particularly valuable if we can tie it in to some other sorts of information. Before I get into that, there are couple variables that I just want to see fuller counts on: table() in R gives the best way to do that. I'm interested in names because I could link them up to census information and because they provide some clues to ethnicity.

#### Reading tables and constructive failure.

Often, if there is something even slightly askew about your input data, `read_csv` will fail. This may be frustrating. Try to be grateful, though, instead. This failure is the first aspect of something we'll encounter many times in this class that is a general feature of data analysis: programs that don't receive *exactly* the input the expect will simply fail to work, usually "throwing" an error message of some sort.

If you have a file previously saved in the csv (comma-separated-value) format, it may be fast to read it it using the `read_csv` function.



You can read it on your computer by typing the following code.


```{r}

library("tidyverse")

read_csv("http://www.whalingmuseum.org/online_exhibits/crewlist/crewlist.csv")
```
You will see some alarming text in red. You can read it or try to understand; but the basic problem is that there are thousands of parsing failures. The reason has to do with the data types we've been talking about. `read_csv` will automatically guess at data types; but it turns out that it's getting some of these wrong because:
1. It doesn't see any eye colors until thousands of entries in;
2. A few ship IDs have letters in them, but it initially learns to read them as numbers.

The first part of our cleaning is just to work around this.

```{r}
crews = read_csv("http://www.whalingmuseum.org/online_exhibits/crewlist/crewlist.csv", guess_max = 1000000)
```

The first thing to do is simply look at. Going to the "Environment" pane in the upper right-hand corner, you can see what's in here.

Where did this data come from? Did they do a good job transcribing? Here's [an example of the original source](http://blogs.archives.gov/prologue/wp-content/uploads/acushnet-crew-list.jpg)

But remember, we're doing programming here, not just browsing (plus, that list is limited to the top 1000.)

R is composed of _functions_: each of these apply on an object. Each is, essentially, a little program of its own: you can run it on data, and see what happens.

In  tidyverse R, the most common data structure is a `data_frame`; it's essentially a table where the rows correspond to observations, and the columns refer to variables.
(tidyverse R borrows this from the incredibly similarly named 'data.frame' object that R has had since its birth. There are basically interchangeable, but using the modern
versions helps you avoid a few pitfalls.)
It resembles a spreadsheet or database table, but every datapoint has a *type*.

In this data set, as you'll see, each row corresponds to an individual crew member, and the columns give information about him, such as the ship he sailed on his, his name, his rank, and so forth.

To look at it, we can start with the simplest program: simply looking at the thing. Type its name and press the green button.

```{r FirstSummary}
crews
```

The first thing to do with a new data source is run `summary`, which figures out what the different columns in your database are and gives appropriate descriptions of the types of data in each. For numbers, it gives averages; for categorical data (called 'factors') in R, it lists the most common elements.

```{r SecondSummary}

summary(crews)

```


#### Other formats

There are many different libraries out there for reading data. R is blessed with many packages for importing them. 

To read Microsoft Excel spreadsheets, it is usually easiest to simply go into Excel and click "save as CSV" to write to a more standard form.

If you don't have Excel (or LibreOffice, the free version), you can read in Excel by using the `gdata` library and its `read.xls` functions.

### Cleaning Data.

There are some obvious problems with the "crews" data we need to fix for analysis.

For example. For example, in the raw version of this dataset:

1. 'Height' is represented as a string like `5' 2 1/2"`, with feet and inches broken out;
2. 'Age' has been read as a string, not a number;
3. 'Date' has been read as a string, so we can't plot--for example--years.

#### An example: cleaning years, and assignment.

We want to extract the years.  

### Using `mutate` and `str_replace` to clean data.

Note that the date doesn't follow a standard form. We're going to use **regular expressions** again to clean it up. Notice the steps in the chain here. We're creating a new column called "year." Then, we feed the output into the function `str_replace`, which lets us use a regular expression.
 
 **Remember the function `str_replace`:** it is among the most important tools for data cleaning in R you will encounter. It lets you use the full power of regular expressions for find-replace operations. This regular expression is complicated--you may have to refer back to your sheet to see what's going on. Note in particular that the parenthesis are performing a **grouping** operation. `str_replace` is a substitution function, so you have to tell it what to replace it with. In this case, the escaped phrase `\\1` tells R to substitute with *the first matched group*. (That's what `\\1` means: `\\2` will match the second matched group, and so forth.)

So: suppose we want to pull 'year' out *as a number*.

The tidyverse has a function `mutate` that changes a dataframe: it either adds a new column, or changes an existing one.

This gets a little complicated, so let's break it down.

*pull* extracts a column so you can look at it more closely. Let's do that with our `ApproximateDeparture` column.

```{r}
crews %>% pull(ApproximateDeparture) %>% head(10)
```

Let's build up a tiny program that extracts the year from this. The first step is to
use regular expressions to get to just the year part of the expression. A simple way
to do that here is to use the `.*` regex operator to replace everything up to and including
a slash with nothing (the empty string, "").

```{r}

crews %>% pull(ApproximateDeparture)  %>% str_replace(".*/", "") %>% head(10)

```

We're not done yet, though, because these are strings and years should be integers.
The function `as.numeric` does this for us. (There's a corresponding function, `as.character`, that
can turn a number into a string.)

```{r}

crews %>% pull(ApproximateDeparture) %>% str_replace(".*/", "") %>% as.numeric %>% head(10) 

```

Success! But while this program runs, it doesn't actually change our original frame.
To do so, we need to do *assignment.*

Finally, we add it to the main file. Now there's a new column called year.

```{r}

crews <- crews %>% mutate(
  year = ApproximateDeparture %>% str_replace(".*/", "") %>% as.numeric
)

```

## Cleaning

In practice, you often do not need to get so far into the nitty-gritty. I do not know of an R function
that would translate feet and inches, but for age and date, we can do this all much more simply.

To turn a string into a number is quite simple; it just takes the function `as.numeric`,
which converts between types. Dates are more complicated. A date **is** a base data type in R,
just like strings and numbers, but there are many different ways of specifying them.
So we use the function `parse_date` with a special string that describes the format:
month-day-year.

This is another formal language, of course, a tiny little one that specifies data formats.
"%m/%d/%Y" means month-day-year (12/7/1945); "%Y-%m-%d" means (1945-12-7). Are you supposed to memorize
all these letters? Of course not. Instead, you just need to know that there's a function for date parsing,
and then use the 'help' documentation in R studio to read about how a particular conversion function works.


```{r}

crews <- crews %>% mutate(
  Age = Age %>% as.numeric,
  date = ApproximateDeparture %>% parse_date("%m/%d/%Y")
)

```



# Exercises: Cleaning and Tidying data

1. Is the data you read in under shiptypes `tidy`?

2. (Hard, skippable) In the crews dataset bundled with the package, I've added 'feet' and 'inches.'
   Here's the code that I used to do it.
   Two hard questions:
   
   * Can you describe what is going on in each line of this?
   * Can you find any examples of heights that this *fails* to detect?
      (One way would be using an 'is.na()' filter)
   

```{r}

crews <- crews %>% mutate(
  feet = Height %>%
    str_replace(" ?ft.? ", "'") %>%
    str_replace("[',] ?.*", "") %>% 
    as.numeric(),
  inches = Height %>% 
    str_replace(" ?ft.? ", "'") %>%
    str_replace("[0-9]'? ?(1?[0-9]).*", "\\1") %>% 
    as.numeric()
)

```

2. Using the `pivot_wider` functions from the `tidyr` package, create a new data.frame that has rows corresponding to ship types and columns corresponding to years. (That is, the exact inverse of the data.frame you saw before.)

``` {r}
library(tidyverse)
library(HumanitiesDataAnalysis)

crews %>%
  count(Rig, ) %>%
  pivot_wider(names_from = Rig, values_from = n)
```

3. There's another file in the `data` directory called CESTACityData.csv. It was graciously provided by the [Center for Spatial and Textual Analysis at Stanford](https://cesta.stanford.edu/). Read it in. We'll be working with this data set more next week.

``` {r}
CESTA
```


4. This data is clearly not tidy. (Why not?) Use `pivot_longer` to turn it into tidy data, and save it as a data.frame called "tidied". (Hint: the final frame will have a column called "year." You may have to use str_replace to remove Xs from the year name.)

``` {r}

```

5. Use the `?` command or the help pane to read about the function `write_csv`. Save the result to disk: we'll be exploring it more next week.

``` {r}

```


### Tidy data for network visualizations.

If you are interested in network visualizations, you can use the `tidygraph` package.

